{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9881c344",
   "metadata": {},
   "source": [
    "#### 1. Install Python (if you don’t have it already) and install NLTK. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86209de",
   "metadata": {},
   "source": [
    "Installed Python and NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2aba1e",
   "metadata": {},
   "source": [
    "#### 2. Follow the instructions in chapter 1 of Bird-Klein for implementing a “lexical diversity” scoring routine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03814b54",
   "metadata": {},
   "source": [
    "Lexical diversity is a measurement of how many different lexical words there are in a text. The lexical diversity of a text can be calculated by taking the ratio of unique types and total types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b57e09db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8451cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d229f2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6842c3",
   "metadata": {},
   "source": [
    "#### 3. Go to http://www.gutenberg.org/ebooks/bookshelf/215  and select texts of different grade levels (e.g., fourth reader, fifth reader et al) Report the lexical diversity score of each. Explain whether the result was surprising."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c2f19d",
   "metadata": {},
   "source": [
    "Below are links to third, fourth and fifth grade books\n",
    " - Third grade: https://www.gutenberg.org/ebooks/15040\n",
    " - Fourth grade: https://www.gutenberg.org/ebooks/14880\n",
    " - Fifth grade: https://www.gutenberg.org/ebooks/15040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c6e6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import re\n",
    "\n",
    "# returns text/tokens\n",
    "def getTextFromUrl(url, text=False):\n",
    "    # make a request\n",
    "    response = request.urlopen(url)\n",
    "\n",
    "    # extract the raw response\n",
    "    raw = response.read().decode('utf8')\n",
    "\n",
    "    # tokenize the words\n",
    "    tokens = nltk.word_tokenize(raw)\n",
    "\n",
    "    if text:\n",
    "        textObj = nltk.Text(tokens)\n",
    "        return textObj\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# get the book title\n",
    "def getBookTitle(url):\n",
    "    # make a request\n",
    "    response = request.urlopen(url)\n",
    "\n",
    "    # extract the raw response\n",
    "    raw = response.read().decode('utf8')\n",
    "\n",
    "    match = re.search(r'Title: ([\\w\\']+) (.+)', raw)\n",
    "    if match:\n",
    "        title = match.group()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return title.strip('\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f04fd508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url for third grade\n",
    "url1 = \"https://www.gutenberg.org/cache/epub/14766/pg14766.txt\"\n",
    "\n",
    "# url for fourth grade\n",
    "url2 = \"https://www.gutenberg.org/cache/epub/14880/pg14880.txt\"\n",
    "\n",
    "# url for fifth grade\n",
    "url3 = \"https://www.gutenberg.org/cache/epub/15040/pg15040.txt\"\n",
    "\n",
    "# create a list with URL's\n",
    "urls = [url1, url2, url3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1054d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the text for each book\n",
    "texts = [getTextFromUrl(url, text=True) for url in urls]\n",
    "\n",
    "# get the token lenght for each book \n",
    "tokens = [len(getTextFromUrl(url, text=False)) for url in urls]\n",
    "\n",
    "# get a list of unique types\n",
    "types = [len(set(getTextFromUrl(url, text=False))) for url in urls]\n",
    "\n",
    "# get book title \n",
    "titles = [getBookTitle(url) for url in urls]\n",
    "\n",
    "# Calculate lexical diversity scores\n",
    "lexicalDiversity = [lexical_diversity(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7a57b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Types</th>\n",
       "      <th>Lexical_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title: McGuffey's Third Eclectic Reader</td>\n",
       "      <td>37993</td>\n",
       "      <td>4713</td>\n",
       "      <td>0.124049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title: McGuffey's Fourth Eclectic Reader</td>\n",
       "      <td>84066</td>\n",
       "      <td>10380</td>\n",
       "      <td>0.123474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title: McGuffey's Fifth Eclectic Reader</td>\n",
       "      <td>126615</td>\n",
       "      <td>14290</td>\n",
       "      <td>0.112862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  Tokens  Types  Lexical_diversity\n",
       "0   Title: McGuffey's Third Eclectic Reader   37993   4713           0.124049\n",
       "1  Title: McGuffey's Fourth Eclectic Reader   84066  10380           0.123474\n",
       "2   Title: McGuffey's Fifth Eclectic Reader  126615  14290           0.112862"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# create a dataframe\n",
    "lexical_summary = pd.DataFrame({'Title': titles, 'Tokens': tokens, 'Types': types,\n",
    "                               'Lexical_diversity': lexicalDiversity})\n",
    "\n",
    "# sort by highest lexical_diversity score\n",
    "lexical_summary.sort_values(by='Lexical_diversity', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22549732",
   "metadata": {},
   "source": [
    "With respect to lexical diversity, we can see that third grade book's lexical diversity score is more than fourth and fifth grade books. At early age, students tend use new words more than later ages. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c056c",
   "metadata": {},
   "source": [
    "#### 4. Also compare the vocabulary size of the same three texts. Explain whether the result was surprising. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20087627",
   "metadata": {},
   "source": [
    "The Vocabulary size is calculated by removing tokens that are not alphabetic tokens and converting them to lower case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1f1dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the vocab size of the 3 texts\n",
    "def getVocabSize(text):\n",
    "    vocab = set(w.lower() for w in text if w.isalpha())\n",
    "    return len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1e1397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabSize = [getVocabSize(text) for text in texts]\n",
    "lexical_summary['Vocabulary_Size'] = vocabSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd901f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Types</th>\n",
       "      <th>Lexical_diversity</th>\n",
       "      <th>Vocabulary_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title: McGuffey's Third Eclectic Reader</td>\n",
       "      <td>37993</td>\n",
       "      <td>4713</td>\n",
       "      <td>0.124049</td>\n",
       "      <td>3684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title: McGuffey's Fourth Eclectic Reader</td>\n",
       "      <td>84066</td>\n",
       "      <td>10380</td>\n",
       "      <td>0.123474</td>\n",
       "      <td>7626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title: McGuffey's Fifth Eclectic Reader</td>\n",
       "      <td>126615</td>\n",
       "      <td>14290</td>\n",
       "      <td>0.112862</td>\n",
       "      <td>10832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  Tokens  Types  Lexical_diversity  \\\n",
       "0   Title: McGuffey's Third Eclectic Reader   37993   4713           0.124049   \n",
       "1  Title: McGuffey's Fourth Eclectic Reader   84066  10380           0.123474   \n",
       "2   Title: McGuffey's Fifth Eclectic Reader  126615  14290           0.112862   \n",
       "\n",
       "   Vocabulary_Size  \n",
       "0             3684  \n",
       "1             7626  \n",
       "2            10832  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by highest lexical_diversity score\n",
    "lexical_summary.sort_values(by='Lexical_diversity', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab1e82",
   "metadata": {},
   "source": [
    "After removing the non-alphabet tokens and converting all tokens to lower case, Fifth grade book has most number of unique words than fouth grade and third grade book has less number of unique words. This make sense as grade level increases, students learn more new words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1386740",
   "metadata": {},
   "source": [
    "#### 5. Write a paragraph arguing whether vocabulary size and lexical diversity in combination could be a better measure of text difficulty (or reading level) than either measure is by itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802b0f7e",
   "metadata": {},
   "source": [
    "When we are comparing text difficulty among different texts with different number of types, lexical diversity alone to measure the text difficultly is not accurate. In other words lexical diversity is dependent on the total number of tokens, if the tokens are a large number like those of Fifth Grade, then even though the Vocabulary size of fifth grade is larger, its lexical diversity is the lowest among all three texts. Thus, it is safe to say that lexical_diversity alone shouldn’t be a measure of text difficulty but it can be used with a thorough Vocabulary analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
